#!/bin/bash

# Script para iniciar la aplicaci√≥n completa con Ollama

echo "=== GP-Test - Iniciando aplicaci√≥n ==="
echo ""

# Verificar e instalar Ollama
OLLAMA_PID=""

# ============================================================================
# CONFIGURACI√ìN DE MODELOS - MEJORES MODELOS SIN RESTRICCIONES
# ============================================================================
# 
# Este proyecto usa los MEJORES modelos disponibles sin restricciones.
# Configurados para M√ÅXIMO RENDIMIENTO, independiente de RAM.
#
# CONSUMO DE RAM:
#   - Mixtral 8x7B: ~12GB RAM (8 expertos, mejor modelo general)
#   - CodeLlama 13B: ~16GB RAM (mejor modelo para c√≥digo)
#   - RAM TOTAL: ~28GB (se cargan uno a la vez, m√°ximo ~16GB simult√°neo)
#
# RAM M√çNIMA RECOMENDADA: 32GB para uso c√≥modo
# RAM M√çNIMA ABSOLUTA: 20GB (con modelos 13B)
#
# Si tienes menos RAM, cambia a modelos 7B (ver opciones abajo)
# ============================================================================

# ‚≠ê MEJORES MODELOS SIN RESTRICCIONES (M√ÅXIMO RENDIMIENTO)
# NOTA: Si tienes menos de 32GB RAM, usa modelos 7B (descomenta las l√≠neas de abajo)
# LLAMA_MODEL="mixtral:8x7b"      # ‚≠ê MEJOR modelo general - 8 expertos (~12GB RAM, pero necesita ~25GB total)
# DEEPSEEK_MODEL="codellama:13b"  # ‚≠ê MEJOR modelo para c√≥digo (~16GB RAM)

# Modelos 7B (balance perfecto para sistemas con 16GB RAM)
LLAMA_MODEL="mistral:7b"       # ~4GB RAM - Muy permisivo y sin restricciones
DEEPSEEK_MODEL="codellama:7b"  # ~4GB RAM - Excelente para c√≥digo

# ALTERNATIVAS si tienes menos RAM:
# Opci√≥n 1: Modelos 7B (balance perfecto, ~8GB RAM total)
# LLAMA_MODEL="mistral:7b"       # ~4GB RAM
# DEEPSEEK_MODEL="codellama:7b"  # ~4GB RAM

# Opci√≥n 2: Modelos 13B individuales (m√°ximo rendimiento, ~16-20GB RAM)
# LLAMA_MODEL="llama2:13b"       # ~16GB RAM
# DEEPSEEK_MODEL="codellama:13b" # ~16GB RAM

echo "üîç Verificando Ollama..."
if ! command -v ollama &> /dev/null; then
    echo "üì¶ Ollama no est√° instalado"
    echo ""
    echo "   Intentando instalar Ollama..."
    echo "   (Esto puede tardar si hay problemas de conexi√≥n)"
    
    # Intentar instalaci√≥n con timeout m√°s largo y reintentos
    if curl --connect-timeout 30 --max-time 300 -fsSL https://ollama.com/install.sh | sh 2>&1; then
        echo "‚úÖ Ollama instalado correctamente"
    else
        echo ""
        echo "‚ö†Ô∏è  Error instalando Ollama autom√°ticamente"
        echo ""
        echo "üìã Opciones para instalar Ollama manualmente:"
        echo ""
        echo "   Opci√≥n 1: Descargar e instalar manualmente"
        echo "   1. Visita: https://ollama.com/download"
        echo "   2. Descarga el instalador para Linux"
        echo "   3. Ejecuta: bash <archivo_descargado>"
        echo ""
        echo "   Opci√≥n 2: Usar el m√©todo alternativo"
        echo "   curl -L https://ollama.com/download/ollama-linux-amd64 -o /tmp/ollama"
        echo "   chmod +x /tmp/ollama"
        echo "   sudo mv /tmp/ollama /usr/local/bin/ollama"
        echo ""
        echo "   Opci√≥n 3: Si ya tienes Ollama instalado en otro lugar"
        echo "   Aseg√∫rate de que est√© en tu PATH"
        echo ""
        read -p "   ¬øQuieres intentar la instalaci√≥n manual ahora? (s/n): " intentar_manual
        
        if [ "$intentar_manual" = "s" ]; then
            echo ""
            echo "   Descargando Ollama manualmente..."
            if curl --connect-timeout 30 --max-time 300 -L https://ollama.com/download/ollama-linux-amd64 -o /tmp/ollama 2>/dev/null; then
                chmod +x /tmp/ollama
                sudo mv /tmp/ollama /usr/local/bin/ollama 2>/dev/null
                if command -v ollama &> /dev/null; then
                    echo "‚úÖ Ollama instalado manualmente"
                else
                    echo "‚ùå Error moviendo Ollama a /usr/local/bin"
                    echo "   Intenta ejecutar: sudo mv /tmp/ollama /usr/local/bin/ollama"
                    exit 1
                fi
            else
                echo "‚ùå Error descargando Ollama manualmente"
                echo "   Por favor inst√°lalo manualmente desde: https://ollama.com"
                exit 1
            fi
        else
            echo ""
            echo "   Por favor instala Ollama manualmente antes de continuar"
            exit 1
        fi
    fi
else
    echo "‚úÖ Ollama est√° instalado ($(ollama --version 2>/dev/null || echo 'versi√≥n desconocida'))"
fi

# Verificar si el servicio Ollama est√° corriendo
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "üöÄ Iniciando servicio Ollama..."
    ollama serve > /tmp/ollama.log 2>&1 &
    OLLAMA_PID=$!
    sleep 3
    
    # Verificar que se inici√≥ correctamente
    if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "‚ö†Ô∏è  El servicio Ollama no se inici√≥ correctamente"
        echo "   Intenta iniciarlo manualmente: ollama serve"
        exit 1
    fi
    echo "‚úÖ Servicio Ollama iniciado"
else
    echo "‚úÖ Servicio Ollama ya est√° corriendo"
fi

# Verificar si los modelos est√°n descargados (SIN restricciones)
echo ""
echo "üîç Verificando modelos (sin restricciones de seguridad)..."
echo "   Modelos seleccionados:"
echo "   - Principal: $LLAMA_MODEL (sin restricciones)"
echo "   - C√≥digo: $DEEPSEEK_MODEL (sin restricciones)"
echo ""
echo "‚è≥ IMPORTANTE: Los modelos se descargar√°n completamente antes de iniciar la aplicaci√≥n."
echo "   Esto puede tardar varios minutos dependiendo de tu conexi√≥n."
echo ""

# Funci√≥n para verificar si un modelo est√° realmente disponible
check_model_available() {
    local model_name=$1
    ollama list 2>/dev/null | grep -q "^$model_name" || ollama list 2>/dev/null | grep -q "$model_name"
}

# Verificar y descargar modelo principal
MODELS=$(ollama list 2>/dev/null || echo "")

if ! check_model_available "$LLAMA_MODEL"; then
    echo "üì• Descargando modelo principal: $LLAMA_MODEL"
    echo "   ‚è≥ Esto puede tomar varios minutos (modelo grande)..."
    echo "   üí° Puedes ver el progreso arriba"
    echo ""
    
    if ollama pull "$LLAMA_MODEL"; then
        # Verificar que realmente se descarg√≥
        if check_model_available "$LLAMA_MODEL"; then
            echo "‚úÖ Modelo principal descargado y verificado: $LLAMA_MODEL"
        else
            echo "‚ö†Ô∏è  Modelo descargado pero no aparece en la lista. Verificando..."
            sleep 2
            if check_model_available "$LLAMA_MODEL"; then
                echo "‚úÖ Modelo principal verificado: $LLAMA_MODEL"
            else
                echo "‚ùå Error: Modelo no disponible despu√©s de descargar"
                echo "   Intenta manualmente: ollama pull $LLAMA_MODEL"
                exit 1
            fi
        fi
    else
        echo "‚ùå Error descargando modelo principal: $LLAMA_MODEL"
        echo "   Verifica tu conexi√≥n a internet y espacio en disco"
        exit 1
    fi
else
    echo "‚úÖ Modelo principal ya est√° disponible: $LLAMA_MODEL"
fi

echo ""

# Verificar y descargar modelo de c√≥digo
if ! check_model_available "$DEEPSEEK_MODEL"; then
    echo "üì• Descargando modelo de c√≥digo: $DEEPSEEK_MODEL"
    echo "   ‚è≥ Esto puede tomar varios minutos (modelo grande)..."
    echo "   üí° Puedes ver el progreso arriba"
    echo ""
    
    if ollama pull "$DEEPSEEK_MODEL"; then
        # Verificar que realmente se descarg√≥
        if check_model_available "$DEEPSEEK_MODEL"; then
            echo "‚úÖ Modelo de c√≥digo descargado y verificado: $DEEPSEEK_MODEL"
        else
            echo "‚ö†Ô∏è  Modelo descargado pero no aparece en la lista. Verificando..."
            sleep 2
            if check_model_available "$DEEPSEEK_MODEL"; then
                echo "‚úÖ Modelo de c√≥digo verificado: $DEEPSEEK_MODEL"
            else
                echo "‚ùå Error: Modelo no disponible despu√©s de descargar"
                echo "   Intenta manualmente: ollama pull $DEEPSEEK_MODEL"
                exit 1
            fi
        fi
    else
        echo "‚ùå Error descargando modelo de c√≥digo: $DEEPSEEK_MODEL"
        echo "   Verifica tu conexi√≥n a internet y espacio en disco"
        exit 1
    fi
else
    echo "‚úÖ Modelo de c√≥digo ya est√° disponible: $DEEPSEEK_MODEL"
fi

echo ""
echo "‚úÖ Todos los modelos est√°n listos. Continuando con la configuraci√≥n..."
echo ""

# Configurar backend
echo "üîß Configurando backend Flask..."
cd Backend

# Verificar si existe venv, si no crearlo
if [ ! -d "venv" ]; then
    echo "üì¶ Creando entorno virtual..."
    python3 -m venv venv
fi

# Activar venv
echo "üîå Activando entorno virtual..."
source venv/bin/activate

# Actualizar pip
echo "‚¨ÜÔ∏è  Actualizando pip..."
pip install --upgrade pip --quiet

# Instalar/actualizar dependencias del backend
echo "üì¶ Instalando dependencias del backend..."
pip install -r requirements.txt

cd ..

# Verificar Node.js y npm
echo "üîç Verificando Node.js y npm..."
if ! command -v node &> /dev/null; then
    echo "‚ùå Node.js no est√° instalado"
    echo ""
    echo "üìã Para instalar Node.js en Kali Linux:"
    echo "   1. curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -"
    echo "   2. sudo apt-get install -y nodejs"
    echo ""
    echo "   O usando nvm:"
    echo "   1. curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash"
    echo "   2. source ~/.bashrc"
    echo "   3. nvm install 18"
    echo ""
    exit 1
fi

if ! command -v npm &> /dev/null; then
    echo "‚ùå npm no est√° instalado"
    echo ""
    echo "üìã npm generalmente viene con Node.js."
    echo "   Si Node.js est√° instalado pero npm no, intenta:"
    echo "   sudo apt-get install npm"
    echo ""
    exit 1
fi

echo "‚úÖ Node.js $(node --version) y npm $(npm --version) detectados"
echo ""

# Configurar frontend
echo "üîß Configurando frontend React..."
cd Frontend

# Verificar si node_modules existe, si no instalar dependencias
if [ ! -d "node_modules" ]; then
    echo "üì¶ Instalando dependencias del frontend..."
    npm install
    if [ $? -ne 0 ]; then
        echo "‚ùå Error instalando dependencias del frontend"
        echo "   Intenta ejecutar manualmente: cd Frontend && npm install"
        cd ..
        exit 1
    fi
else
    echo "‚úÖ Dependencias del frontend ya instaladas"
fi

cd ..

# Iniciar backend con venv activo
echo ""
echo "üöÄ Iniciando backend Flask..."
cd Backend
source venv/bin/activate
python app.py &
BACKEND_PID=$!
cd ..

# Esperar a que el backend est√© listo
echo "‚è≥ Esperando a que el backend est√© listo..."
sleep 3

# Iniciar frontend
echo "üöÄ Iniciando frontend React..."
cd Frontend
if command -v npm &> /dev/null; then
    npm start &
    FRONTEND_PID=$!
else
    echo "‚ùå npm no disponible para iniciar el frontend"
    FRONTEND_PID=""
fi
cd ..

echo ""
echo "‚úÖ Aplicaci√≥n iniciada!"
echo "   Backend: http://localhost:5000"
echo "   Frontend: http://localhost:3000"
echo "   Ollama: http://localhost:11434"
echo ""
echo "Presiona Ctrl+C para detener todos los servicios"

# Esperar a que el usuario presione Ctrl+C
cleanup() {
    echo ""
    echo "üõë Deteniendo servicios..."
    kill $BACKEND_PID 2>/dev/null
    if [ ! -z "$FRONTEND_PID" ]; then
        kill $FRONTEND_PID 2>/dev/null
    fi
    if [ ! -z "$OLLAMA_PID" ]; then
        kill $OLLAMA_PID 2>/dev/null
    fi
    exit
}
trap cleanup INT TERM
wait
